# Visual Place Recognition :A Survey

## Abstract

首先，引入视觉位置识别的概念以及位置识别系统的主要组件。
然后，在忽略环境外观变化的情况下，给出位置识别的解决方案。
再次，在考虑环境变化的情况下，给出位置识别的解决方案
最后，结合深度学习，语义分割，视频描述，讨论位置识别的未来。

## Introduction

定义：一个位置识别系统需要做的是，像人或动物一样，识别出当前这个地方我曾经来过。这是一个较难的领域，是因为环境总是具有挑战性的变化。

首先，一个位置识别系统需要有一个内部表示的地图，去和当前输入的图像做比较；

其次，必须系统最后需要报告一个置信度，最近的视觉信息是否包含在之前的地图中。

【1-19】定位和位置识别算法。

涉及领域包括：机器人、计算机视觉、神经学、深度学习、SLAM、localization、mapping、recognition

## Concept of place in robotics and the natural kingdom

【20】老鼠导航提出认知地图的概念，相关还有【23，24，25，26】

自然界的位置概念有认知地图，【23】提出认知地图应包括路径、边、节点、区域和路标，其在机器人领域中由【24、25】应用并提出有语义层级的认知地图。此后发现位置细胞【28、29、30】，由【31】提出位置细胞形成认知地图，【32、33】发现朝向细胞以及网格细胞，综合构建了脑部导航的模型。【35、36】研究发现当场景发生变化时，位置细胞也会根据外部的路标更新正确的位置信息。对于机器人而言则主要是拓扑和度量关系。

视觉位置识别系统包括：图像处理模块、置信生成模块（新位置还是老位置）、地图

<img src="C:\Users\djr\AppData\Roaming\Typora\typora-user-images\image-20220117210745512.png" alt="image-20220117210745512" style="zoom:50%;" />

## What is a place?

机器人的位置概念是被导航与建图问题所引出来的，因为不准确的传感器和驱动器导致建图困难，而SLAM【37-41】问题则更加困难。

拓扑地图？？？

此处都不太懂



## Describing places : the image processing module

视觉位置描述技术可以分为两种：有选择的提取图像中的兴趣点或者值得注意的点（local feature descriptors）【SIFT、SURF】，或者直接对整幅图像进行处理（[global](https://so.csdn.net/so/search?q=global&spm=1001.2101.3001.7020) descriptors）【Gist】。

### A. Local Feature Descriptors

[76]-[83]广泛使用了SIFT，[84]使用了[85]提出的Harris affine regions，[86、87]使用SURF，[2]使用了[88]提出的CenSurE。局部特征提取分为检测和描述，两步可以使用不同技术。[89]用[90]的FAST检测，用SIFT描述，[15]则使用FAST检测，用[91]BRIEF描述。

一幅图像的特征很多，所以使用[92]的bag-of-words模型，[93]将特征量化为词汇表，可以使用[94]的retrieval techniques。词袋模型将特征描述子空间划分成有限数目的视觉单词。每一幅图像中的所有特征都被归类到了单词中，忽略几何及空间结构。因此使得图像缩减成长度为n的二进制串或者直方图的形式，n是词汇表中单词的数量。

词袋模型可以将图像使用二进制串的汉明距离或者直方图比较技术来对比，而词汇树模型可以提升大规模场景识别时的效率[82、84、87、96、97]使用了词袋模型。

由于词袋模型忽视了几何信息，因此场景描述是姿态不变的。但[14、87、98-100]发现增加几何信息可以增强在不良条件下的鲁棒性。这些系统可能假设激光传感器可用于3-D信息[98]，使用双目视觉[14]、对几何约束[100]、[101]，或者简单地根据图像中元素的位置定义场景几何[102]、[103]。位姿不变性(不考虑机器人姿态的情况下进行位置识别)与场景不变性(视觉外观变化时进行位置识别)之间的权衡尚未得到解决，是当前位置识别研究的一个挑战。

词袋模型需要事先训练，而且转换场景后要重训练，所以[56]提出在线训练的方法，这样就避免了预训练步骤且能自适应环境。

### B. Global Descriptors

全局场景描述子早期用颜色直方图【5】以及principal component analysis【104】主成分分析；[105]使用了各种图像特征，例如[106]使用的边，[107]的角，以及色块，来组成一个位置的指纹，将这些特征按0~360度排列，则场景识别就变成了串匹配，这里使用的全景相机，允许在每个位置进行旋转不变匹配。

局描述子也可以利用预定义图像关键点从局部描述子得到。[108]使全图描述子基于SURF特征提取得到WI-SURF来表示位置，BRIEF-Gist则是用BRIEF特征【91】描述。

目前常用的是Gist【74、75】应用到许多场景【110-113】

### C. Describing places using local and global techniques

两者各有优劣，可相互结合。

- 局部特征法可以结合度量信息，来校正定位。
- 全局描述对机器人位姿敏感。
- 局部特征子可以重组，生成未见过的place。
- 局部特征法对环境条件变化敏感，但全局描述法可胜任。

> Using global descriptors on image segments rather than whole images may provide a compromise between the two approaches, as sufficiently large image segments exhibit some of the condition invariance of whole images, and sufficiently small image segments exhibit the pose invariance of local features.

参考的文献暂不列举。

### D. Including three-dimensional information in place descriptions

上述描述的图像处理技术是基于外观的，“直接在外观上建模数据”。然而，在度量地位系统中，基于外观的模型必须使用度量信息进行扩展。单目图像数据不是几何地标的天然来源——世界的基本几何结构不会像激光数据那样从图像中“突出”出来【125】。虽然许多系统使用来自额外传感器的数据，如激光[98]或RGB-D相机[126]-[128]，但几何数据也可以从传统相机中提取，以实现机器人姿态的度量计算。

度量距离信息可以使用双目摄像机[2、129-131]来推断。单目相机也可以使用从运动中提取结构的算法来推断度量信息[132]。方法包括MonoSLAM[7]、PTAM[133]、DTAM[134]、LSD-SLAM[135]和ORB-SLAM[136]。度量信息可以是稀疏的:即距离测量与局部特征相关联，如MonoSLAM[7]中的图像块，[76]中的SIFT特征，FrameSLAM[2]中的CenSurE特征，或ORB-SLAM的ORB特征[137、136]。

==相比之下，DTAM存储了每个像素的密集度量信息，而LSD-SLAM则保存了包含结构和信息的图像部分的半密集深度数据。密集的度量数据允许机器人执行避障、度量规划以及映射和定位;因此，可以在[16]中执行完全自主的纯视觉导航。==

新型传感器的引入，如RGB-D相机，提供密集深度信息和图像数据，刺激了密集建图技术[70]、[126]-[128]、[138]、[139]的发展。这些传感器还可以利用三维物体信息来提高位置识别。SLAM++[70]存储了一个三维对象模型数据库，在导航时使用该数据库进行对象识别，并将这些对象作为高级位置特征。与底层的位置特性相比，对象有很多优势:它们提供丰富的语义信息，并可以通过语义压缩减少内存需求，即存储对象标签，而不是在建图中存储完整的对象模型[70]。

## Remembering places : The mapping module

对于一个位置识别或导航任务，系统需要参考地图(机器人对世界的知识的存储表示)，并将当前的观察结果与地图进行比较。地图框架的不同取决于可用的数据和正在执行的位置识别的类型。表I显示了建图方法的分类，这取决于建图中的物理抽象级别，以及位置描述中是否包含度量信息。列出的最具体的建图框架是拓扑度量或地形图。

### A. Pure image retrieval

### B. Topological Maps

### C. Topological-Metric Maps





